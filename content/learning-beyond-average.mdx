---
title: "Learning to Design Beyond the Average: A Designer's Journey with Todd Rose's Principles"
excerpt: "An exploration of how Todd Rose's research on the myth of average challenges traditional UX design assumptions and opens new possibilities for truly adaptive experiences."
publishedAt: "2025-07-20"
category: "apply"
tags: ["design", "learning", "cognition", "user-experience"]
status: "published"
featured: false
---

# Learning to Design Beyond the Average: A Designer's Journey with Todd Rose's Principles

*How a random internet rabbit hole led me to question everything I thought I knew about users, averages, and what it means to design for real people.*

---

## The rabbit hole that changed my perspective

Last year, I found myself in one of those wonderful internet rabbit holes that designers know well. I'd been wrestling with questions about AI-powered user experiences—specifically, how to create systems that actually adapt to individuals rather than just serving up slightly personalized versions of the same thing to everyone.

I was stuck on something fundamental: **How do you design for uniqueness at scale?**

Then I stumbled across Todd Rose's TEDx talk about "The Myth of Average." Rose, a researcher at Harvard, opened with a story that made me pause my note-taking app and actually listen:

> In the 1950s, the U.S. Air Force was losing pilots. Their cockpits were designed for the "average" pilot—carefully calculated measurements across thousands of airmen. But pilots kept crashing. When researcher Gilbert Daniels measured 4,063 pilots across just ten body dimensions, he found that **zero pilots—not one—fit the average profile on all dimensions.**

As a designer who'd spent years creating "user personas" based on demographic averages, this hit like a cold splash of water.

## The uncomfortable realization about personas

Rose's story forced me to confront something uncomfortable about my own design practice. How many times had I said things like "our typical user is a 32-year-old professional who..." or made decisions based on aggregate user research data?

I started thinking about the recommendation algorithms I'd been studying. Netflix's system, which I'd always admired, suddenly seemed more complex than I'd realized. It wasn't just serving "movies for 20-somethings" or "content for busy parents." It was recognizing that the same person might want entirely different things on Tuesday evening versus Saturday morning.

This led me deeper into Rose's work, particularly his book *The End of Average*. What I found there gave me a framework that felt like it could transform how we think about AI-powered design.

## Three principles that reframe everything

Rose articulates three principles of individuality that, once you see them, you can't unsee:

### 1. Jaggedness: We're all multidimensional and contradictory

**The insight:** No one is consistently "high" or "low" across all dimensions. We're jagged—excellent at some things, average at others, struggling with still others.

**What this means for design:** Those neat user personas we create? They're fiction. Real people are wonderfully contradictory. Someone might be incredibly tech-savvy but prefer simple interfaces when they're stressed. They might love complexity in their hobby apps but want their banking app to be braindead simple.

I started noticing this in my own behavior. I'm comfortable with complex design tools but get frustrated with overly clever microinteractions in my note-taking app. I want my learning apps to challenge me but my weather app to just tell me if I need an umbrella.

**The design implication:** Instead of asking "what do users want," we need to ask "what does *this* user want *in this context* for *this task*?"

### 2. Context: Behavior is situational, not fixed

**The insight:** There are no stable personality traits that predict behavior across all situations. The same person acts completely differently in different contexts.

This resonated deeply with my background in education. I'd seen students who were quiet in large groups become animated discussion leaders in small ones. Students who struggled with traditional tests but excelled in project-based assessments.

**What this means for design:** Context isn't just "mobile vs. desktop" or "morning vs. evening." It's emotional state, social environment, task urgency, energy level, and dozens of other factors we rarely consider.

Spotify seems to understand this. Their Discover Weekly playlist isn't just "music you might like"—it's "music you might like for Monday morning discovery listening." Different context, different music, even for the same person.

**The design implication:** We need to design systems that can detect and adapt to context changes, not just user preferences.

### 3. Pathways: There are many ways to succeed

**The insight:** There's no single "optimal" path to any goal. Different people need different routes, and that's not a bug—it's a feature.

This principle particularly speaks to my interest in pedagogy. In education, we've learned that some students need to see the big picture first, others need to build up from details. Some learn by doing, others by reflecting. The "optimal" learning path depends entirely on the individual.

**What this means for design:** Our carefully crafted user flows—those neat linear paths from awareness to conversion—might be optimal for no one.

Amazon seems to grasp this. You can find products through search, browsing categories, recommendations, wish lists, or following links from reviews. Multiple pathways to the same goal.

**The design implication:** We should design multiple ways to accomplish the same task and let users gravitate toward what works for them.

## Where this gets really interesting (and hard)

As I've been thinking about these principles, I keep coming back to the same tension: **How do you operationalize individuality without losing your mind?**

The Air Force solved their cockpit problem by making things adjustable. Simple, elegant, effective. But software interfaces aren't airplane seats. The solution space is multidimensional and the adaptation possibilities are nearly infinite.

Here's what I'm learning:

### Start with progressive disclosure, not progressive complexity

Instead of trying to be all things to all people, start simple and reveal complexity as needed. Let users show you their jaggedness over time rather than trying to capture it upfront.

### Design for context changes, not just user preferences  

Build systems that can recognize when someone's context has shifted. If a user who normally spends 20 minutes reading articles suddenly starts skimming, that's a signal worth paying attention to.

### Offer pathways, don't prescribe them

Give people multiple ways to accomplish their goals. Track which paths work for which people in which contexts. Learn from that, but don't force it.

## The pedagogy connection

What excites me most about Rose's principles is how they connect to what we know about learning. The best educational experiences are adaptive—they meet learners where they are, adjust to their context, and offer multiple pathways to mastery.

Maybe the future of UX isn't about designing interfaces at all. Maybe it's about designing systems that can learn to teach themselves to each user.

I'm thinking about apps that don't just personalize content but personalize interaction patterns. Systems that learn not just what you like but how you like to discover it, process it, and act on it.

## Questions I'm still wrestling with

This framework has opened up more questions than answers for me:

- How do we balance personalization with serendipity? If systems get too good at predicting what we want, do we lose the joy of discovery?
- What are the ethical implications of systems that know us better than we know ourselves?
- How do we maintain user agency in adaptive systems? How do we avoid creating digital environments that shape us more than we shape them?
- From a practical standpoint, how do we design and test for individuality? Traditional A/B testing assumes population-level insights apply to individuals. But what if they don't?

## What I'm experimenting with

I've started incorporating these ideas into my design practice in small ways:

**In user research:** Instead of just asking what people prefer, I'm asking about context. When do you want this feature? When would it be annoying? How does your usage change based on your mood, location, or time constraints?

**In interface design:** I'm building in more optional pathways and progressive disclosure. Testing whether people actually use the multiple routes I'm providing or if I'm just creating complexity for complexity's sake.

**In thinking about AI:** Moving beyond "what should the algorithm recommend?" to "how should the algorithm learn to recommend differently for different people in different contexts?"

## The learning continues

Rose's principles have given me a new lens for thinking about the intersection of human individuality and technological possibility. But like any good framework, they've raised more questions than they've answered.

I'm still figuring out how to operationalize these ideas in real products with real constraints. I'm still learning how to balance the desire for individualization with the need for coherent, learnable interfaces.

But I'm convinced we're on the right track. The era of designing for the "average user" is ending, not because the average is meaningless, but because we finally have the tools to do better.

The question isn't whether to embrace individual differences in our design—it's how quickly we can learn to do it well.

---

*What's your take on designing for individuality? Have you noticed patterns in your own behavior that don't fit the "average user" mold? I'd love to hear about your experiences—drop me a line or share your thoughts.*